#!/bin/sh
#
# This is a simple statis website generator script.
#
KVH_COPYRIGHT="Copyright (C) 2021-2025 Mahdi Mirzadeh"
KVH_VERSION="0.3"
KVH_SRC="${PWD}/.src"
KVH_DST="${PWD}"

# Default page values
KVH_PAGE_NAME="Kaveh"
KVH_PAGE_ICON="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAACXBIWXMAAAFxAAABcQG7iuH0AAAAGXRFWHRTb2Z0d2FyZQB3d3cuaW5rc2NhcGUub3Jnm+48GgAAAhVJREFUOI2FkU1IlHEQxn/z33fbJSIIDx0ioUChj0Mm7R7KNRc7SAUdyiDCDoqXCC9BeKpTHYRIyFMRBBWEUFCgh0rIbFM3lKAsSKJLEn2Z7Yfr7vvOdAjD6FXnNPA8/GaeGVilekZS7ReG9x9ZTnerAVSkLUC6ukaaq8N0b2K6tm12IRbJ+7FM3pfGQhCd7ExksgCXM+lNvgXbRfgW8e080P4fwIxzgnb7lAtYLA52v29039uyCmrBekzuOvEuQnAtdAPBvqR3vHkAcHsyOUggxwz6/6STaoQ4sfhP8oXQiB7A0NTOR3OVNRR9dSbulcGsAGBxjG4tFtLAdChgd837ppWO2PO88ThwCywapq/6BcOGxGyX4rJhuiw298YSVcWoNhUqUamok4q6M4G5kgI5dRRVbuR811wwV8j57lk+gLzKd28RoGs0iUqfc1wydQEic2f3Pj20dFrnk/S4mdzE6WsJJCniGv5GOFr3csBBB0ariwSjK2R6B2DiNqsj9c8NTtRnHwaqp0wjvcsCxFpN3ZaqwrqW7MGBzxLmuTqWqPI13m++dpSABeLMAfMlqn9Bx50Dj08uer0wwOnE+I/eTMMLdZEhD4ZLfjAvJntU3AxwZak3EgbY0JLcKM59UnN1anZ9Qdxw2WRrGRlcUD5sO1z/dap/ypbdwMOrr5hLgUyISEoCQYwZjNoIria3tvgRmAX4DdT85ywDHCURAAAAAElFTkSuQmCC"
KVH_PAGE_DESC="Kaveh is a simple website generator, it aims to generate static html files from markdown files, no databases and bloat-web, just texts."
KVH_SITEMAP=""

while getopts :vi:o:s: flag; do
    case "${flag}" in
        i) KVH_SRC=${OPTARG%/};;
        o) KVH_DST=${OPTARG%/};;
        s) KVH_SITEMAP=${OPTARG};;
        v)
            printf "\n"
            printf " _  __               _      \tKaveh v%s\n" "${KVH_VERSION}"
            printf "| |/ /__ ___   _____| |__   \t%s\n" "${KVH_COPYRIGHT}"
            printf "| ' // _\` \ \ / / _ \ '_ \ \t\n"
            printf "| . \ (_| |\ V /  __/ | | | \tThis program may be freely redistributed under\n"
            printf "|_|\_\__,_| \_/ \___|_| |_| \tthe terms of the MIT License.\n"
            printf "\n"
            exit
        ;;
        *)
            printf "%s [-v] [-i SOURCE_DIR] [-o OUTPUT_DIR] [-s BASE_URL]\n" "$0"
            exit
        ;;
    esac
done

# Convert paths to absolute to ensure proper relative path handling
if [ -d "${KVH_SRC}" ] || [ -f "${KVH_SRC}" ]; then
    # Source exists, get its absolute path
    KVH_SRC=$(cd "$(dirname "${KVH_SRC}")" 2>/dev/null && pwd)/$(basename "${KVH_SRC}")
fi

# Ensure destination is absolute path
if [ -d "${KVH_DST}" ]; then
    # Destination directory exists, get its absolute path
    KVH_DST=$(cd "${KVH_DST}" 2>/dev/null && pwd)
else
    # Destination doesn't exist, resolve parent and append basename
    DST_PARENT=$(dirname "${KVH_DST}")
    DST_BASE=$(basename "${KVH_DST}")
    if [ -d "${DST_PARENT}" ]; then
        KVH_DST=$(cd "${DST_PARENT}" 2>/dev/null && pwd)/${DST_BASE}
    else
        # Parent doesn't exist either, create it or use relative path as-is
        mkdir -p "${DST_PARENT}" 2>/dev/null && KVH_DST=$(cd "${DST_PARENT}" 2>/dev/null && pwd)/${DST_BASE}
    fi
fi

# Determine source root directory for header/footer resolution
if [ -f "${KVH_SRC}" ]; then
    KVH_SRC_ROOT=$(cd "$(dirname "${KVH_SRC}")" 2>/dev/null && pwd)
else
    KVH_SRC_ROOT="${KVH_SRC}"
fi

getvalue() {
    awk -v key="$2" '
        /<!---/,/--->/{
            if (tolower($0) ~ "^" tolower(key) ":") {
                sub(/^[^:]+:[[:space:]]*/, "")
                print
                exit
            }
        }
    ' "$1"
}

get_output_filename() {
    # Determine output filename avoiding conflicts with source files
    # $1 = desired output path (e.g., "index.html" or "blog/post.html")
    local desired_path="$1"
    local dir_part=$(dirname "$desired_path")
    local file_part=$(basename "$desired_path")
    local name_part="${file_part%.*}"
    local ext_part="${file_part##*.}"
    
    # Build full path to check in source
    local check_path
    if [ "$dir_part" = "." ]; then
        check_path="${KVH_SRC}/${file_part}"
    else
        check_path="${KVH_SRC}/${dir_part}/${file_part}"
    fi
    
    # If no conflict, return the desired path
    if [ ! -e "$check_path" ]; then
        echo "$desired_path"
        return
    fi
    
    # Conflict exists, try with underscore suffix
    local suffix="_"
    local suffix_num=""
    
    while true; do
        local test_name="${name_part}${suffix}${suffix_num}.${ext_part}"
        if [ "$dir_part" = "." ]; then
            check_path="${KVH_SRC}/${test_name}"
        else
            check_path="${KVH_SRC}/${dir_part}/${test_name}"
        fi
        
        if [ ! -e "$check_path" ]; then
            if [ "$dir_part" = "." ]; then
                echo "$test_name"
            else
                echo "${dir_part}/${test_name}"
            fi
            return
        fi
        
        if [ -z "$suffix_num" ]; then
            suffix_num="2"
        else
            suffix_num=$((suffix_num + 1))
        fi
    done
}

get_pagination_dirname() {
    # Determine pagination directory name avoiding conflicts
    # $1 = source file, $2 = base name (default if no custom), $3 = custom_dir (optional)
    local src_file="$1"
    local base_name="$2"
    local custom_dir="$3"
    
    # Use custom directory if provided, otherwise use base name
    local desired_name="${custom_dir:-$base_name}"
    
    # Check if desired name conflicts with source content
    if [ ! -e "${KVH_SRC}/${desired_name}" ]; then
        # No conflict, use the desired name directly
        echo "${desired_name}"
        return
    fi
    
    # Conflict exists, try with underscore suffix
    local suffix="_"
    local suffix_num=""
    
    while [ -e "${KVH_SRC}/${desired_name}${suffix}${suffix_num}" ]; do
        if [ -z "$suffix_num" ]; then
            suffix_num="2"
        else
            suffix_num=$((suffix_num + 1))
        fi
    done
    
    echo "${desired_name}${suffix}${suffix_num}"
}

get_file_icon() {
    # Get minimal SVG icon based on file extension/type
    # $1 = file extension (lowercase)
    local ext="$1"
    
    # Map extensions to icon types
    case "$ext" in
        # Images
        jpg|jpeg|png|gif|svg|webp|bmp|ico)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M1.75 2.5a.25.25 0 0 0-.25.25v10.5c0 .138.112.25.25.25h.94a.76.76 0 0 1 .03-.03l6.077-6.078a1.75 1.75 0 0 1 2.412-.06L14.5 10.31V2.75a.25.25 0 0 0-.25-.25Zm12.5 11H4.81l5.048-5.047a.25.25 0 0 1 .344-.009l4.298 3.889v.917a.25.25 0 0 1-.25.25ZM1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25V2.75A1.75 1.75 0 0 0 14.25 1ZM5.5 6a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0ZM7 6a2 2 0 1 0-4 0 2 2 0 0 0 4 0Z"></path></svg>'
        ;;
        # Videos
        mp4|webm|mkv|avi|mov|wmv|flv|m4v)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M1.75 2.5A1.75 1.75 0 0 0 0 4.25v7.5C0 12.99.784 14 1.75 14h12.5A1.75 1.75 0 0 0 16 12.25v-7.5A1.75 1.75 0 0 0 14.25 2.5ZM1.5 4.25a.25.25 0 0 1 .25-.25h12.5a.25.25 0 0 1 .25.25v7.5a.25.25 0 0 1-.25.25H1.75a.25.25 0 0 1-.25-.25ZM6 10.75a.75.75 0 0 1-.75.75h-1.5a.75.75 0 0 1 0-1.5h1.5a.75.75 0 0 1 .75.75Zm4.75.75a.75.75 0 0 0 0-1.5h-1.5a.75.75 0 0 0 0 1.5Z"></path></svg>'
        ;;
        # Audio
        mp3|wav|ogg|flac|aac|m4a|wma)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M11.5 1.429v13.142a1.429 1.429 0 0 1-2.571 0V1.429a1.429 1.429 0 0 1 2.571 0Zm-4 2.857v10.285a1.429 1.429 0 0 1-2.571 0V4.286a1.429 1.429 0 0 1 2.571 0Z"></path></svg>'
        ;;
        # Archives
        zip|tar|gz|bz2|xz|7z|rar|tgz)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M6.75 0h2.5v2h-2.5Zm2.5 2v2h-2.5V2ZM6.75 4h2.5v2h-2.5Zm0 4h2.5v2h-2.5Zm-1.5 1.5v-1h1v1a.75.75 0 0 1-1.5 0Zm-2.5-6A1.75 1.75 0 0 0 1 5.25v8.5C1 14.99 1.784 16 2.75 16h10.5A1.75 1.75 0 0 0 15 14.25v-8.5A1.75 1.75 0 0 0 13.25 4H9.5V2h3.75c.69 0 1.25.56 1.25 1.25v11c0 .69-.56 1.25-1.25 1.25H2.75C2.06 15.5 1.5 14.94 1.5 14.25v-11C1.5 2.56 2.06 2 2.75 2H5.5v2H2.75Z"></path></svg>'
        ;;
        # Documents
        pdf)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M4 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2Zm.5 3.5h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1 0-1Zm0 2h6a.5.5 0 0 1 0 1h-6a.5.5 0 0 1 0-1Zm0 2h6a.5.5 0 0 1 0 1h-6a.5.5 0 0 1 0-1Zm0 2h6a.5.5 0 0 1 0 1h-6a.5.5 0 0 1 0-1Zm0 2h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1 0-1Z"></path></svg>'
        ;;
        doc|docx|odt|txt|rtf)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>'
        ;;
        # Spreadsheets
        xls|xlsx|ods|csv)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h3v-8Zm4.5 0v8h3.25a.25.25 0 0 0 .25-.25V6.5ZM6.5 5h3V1.5h-3Zm-1.5 1.5v8H1.75a.25.25 0 0 1-.25-.25V6.5Zm0-1.5V1.5H1.75a.25.25 0 0 0-.25.25V5Zm6.5 0V1.5h3.25c.138 0 .25.112.25.25V5Z"></path></svg>'
        ;;
        # Code
        html|css|js|json|xml|yml|yaml)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg>'
        ;;
        # Executables/binaries
        exe|bin|app|dmg|deb|rpm)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm7-3.25v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5a.75.75 0 0 1 1.5 0Z"></path></svg>'
        ;;
        # Keys/certificates
        gpg|pgp|asc|key|pem|crt|cer)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M6.5 5.5a4 4 0 1 1 2.731 3.795.75.75 0 0 0-.768.18L7.44 10.5H6.25a.75.75 0 0 0-.75.75v1.19l-.06.06H4.25a.75.75 0 0 0-.75.75v1.19l-.06.06H1.75a.25.25 0 0 1-.25-.25v-1.69l5.024-5.023a.75.75 0 0 0 .181-.768A3.995 3.995 0 0 1 6.5 5.5ZM4.5 0a6.5 6.5 0 0 0-5.348 10.129 1.75 1.75 0 0 0-.102.623v3.498c0 .966.784 1.75 1.75 1.75h3.5a1.75 1.75 0 0 0 1.238-.513l.457-.457c.141-.14.22-.333.22-.53V13.5a.25.25 0 0 1 .25-.25h1a.25.25 0 0 1 .25.25v1a1.75 1.75 0 0 0 1.75 1.75h1a.25.25 0 0 1 .25.25V15a1.75 1.75 0 0 0 1.75 1.75h2.086a1.75 1.75 0 0 0 1.238-.513A6.5 6.5 0 1 0 4.5 0ZM9 5.5a1 1 0 1 1 2 0 1 1 0 0 1-2 0Z"></path></svg>'
        ;;
        # Default for unknown types
        *)
            echo '<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>'
        ;;
    esac
}

process_lists() {
    # Process list directives in markdown file
    # $1 = input file
    local input_file="$1"
    
    # Check if file contains list directive
    if ! grep -q '<!---list' "${input_file}" 2>/dev/null; then
        cat "${input_file}"
        return
    fi
    
    # Process list directives
    awk -v src_dir="${KVH_SRC}" '
        /<!---list$/ {
            # Multi-line YAML-like syntax
            pattern = ""
            per_page = 999
            custom_dir = ""
            icon = "auto"
            date = "auto"
            display_next = "Next →"
            display_prev = "← Previous"
            
            # Read until closing --->
            while (getline > 0) {
                if ($0 ~ /^--->$/) break
                
                # Parse key: value pairs (spaces after colon are optional)
                if (match($0, /^[[:space:]]*pattern:[[:space:]]*(.+)$/, arr)) {
                    pattern = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", pattern)
                }
                else if (match($0, /^[[:space:]]*per_page:[[:space:]]*([0-9]+)$/, arr)) {
                    per_page = arr[1]
                }
                else if (match($0, /^[[:space:]]*custom_dir:[[:space:]]*(.+)$/, arr)) {
                    custom_dir = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", custom_dir)
                }
                else if (match($0, /^[[:space:]]*icon:[[:space:]]*(.+)$/, arr)) {
                    icon = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", icon)
                }
                else if (match($0, /^[[:space:]]*date:[[:space:]]*(.+)$/, arr)) {
                    date = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", date)
                }
                else if (match($0, /^[[:space:]]*display_next:[[:space:]]*(.+)$/, arr)) {
                    display_next = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", display_next)
                    # Remove quotes if present
                    gsub(/^"|"$/, "", display_next)
                    gsub(/^'\''|'\''$/, "", display_next)
                }
                else if (match($0, /^[[:space:]]*display_prev:[[:space:]]*(.+)$/, arr)) {
                    display_prev = arr[1]
                    gsub(/^[[:space:]]+|[[:space:]]+$/, "", display_prev)
                    # Remove quotes if present
                    gsub(/^"|"$/, "", display_prev)
                    gsub(/^'\''|'\''$/, "", display_prev)
                }
            }
            
            if (pattern != "") {
                if (custom_dir != "") {
                    print "__KVHLIST__" pattern "__" per_page "__1__0__" custom_dir "__" icon "__" date "__" display_next "__" display_prev "__"
                } else {
                    print "__KVHLIST__" pattern "__" per_page "__1__0____" icon "__" date "__" display_next "__" display_prev "__"
                }
            }
            next
        }
        { print }
    ' "${input_file}"
}

generate_post_list() {
    # $1 = source directory, $2 = pattern, $3 = page number, $4 = per_page, $5 = current file, $6 = list_id, $7 = total lists, $8 = custom_dir, $9 = icon, $10 = date, $11 = display_next, $12 = display_prev
    local src_dir="$1"
    local pattern="$2"
    local page="${3:-1}"
    local per_page="${4:-10}"
    local current_file="${5:-index.html}"
    local list_id="${6:-1}"
    local total_lists="${7:-1}"
    local custom_dir="$8"
    local icon="${9:-auto}"
    local date_opt="${10:-auto}"
    local display_next="${11:-Next →}"
    local display_prev="${12:-← Previous}"
    
    # Get list of files sorted by date (newest first)
    # Use -path to match full paths, or -name if pattern has no path component
    local files
    if echo "$pattern" | grep -q '/'; then
        # Pattern has path component, use -path
        files=$(find "${src_dir}" -type f -path "*/${pattern}" \
                ! -name "${KVH_HDR_FILE}" ! -name "${KVH_FTR_FILE}" 2>/dev/null | sort -r)
    else
        # Pattern has no path (e.g., '*', '*.md'), use -name to match in src_dir root
        files=$(find "${src_dir}" -maxdepth 1 -type f -name "${pattern}" \
                ! -name "${KVH_HDR_FILE}" ! -name "${KVH_FTR_FILE}" 2>/dev/null | sort -r)
    fi
    local total=$(echo "$files" | wc -l)
    
    [ -z "$files" ] && return
    
    # Calculate pagination
    local total_pages=$(( ($total + $per_page - 1) / $per_page ))
    local start=$(( ($page - 1) * $per_page + 1 ))
    local end=$(( $page * $per_page ))
    [ $end -gt $total ] && end=$total
    
    # Start output with short, collision-resistant ID (§l = list)
    printf '<div class="post-list" id="§l%d">\n' "$list_id"
    
    # Process files using awk to handle line numbers
    echo "$files" | awk -v start="$start" -v end="$end" -v src_dir="$src_dir" '
        NR >= start && NR <= end {
            print $0
        }
    ' | while IFS= read -r file; do
        # Extract filename
        filename=$(basename "$file")
        
        # Extract date from filename (YYYY-MM-DD pattern)
        date=$(echo "$filename" | grep -o '[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}')
        
        # Check if file is markdown
        if [ "${file%.md}" != "$file" ]; then
            # Markdown file - extract metadata
            title=$(getvalue "$file" "title")
            if [ -z "$title" ]; then
                title=$(echo "$filename" | sed -e 's/\.md$//' -e 's/^[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}-//' -e 's/-/ /g')
                title=$(echo "$title" | awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
            fi
            desc=$(getvalue "$file" "description")
            # Generate relative URL (convert .md to .html)
            url=$(echo "$file" | sed -e "s|^${src_dir}/||" -e 's/\.md$/.html/')
            
            # Get file modification time for markdown files (when date: true)
            file_mtime_iso=$(date -r "$file" "+%Y-%m-%dT%H:%M:%S%z" 2>/dev/null || true)
            file_mtime_display=$(date -r "$file" "+%Y-%m-%d %H:%M" 2>/dev/null || true)
            if [ -z "$file_mtime_display" ]; then
                # Fallback using ls if date -r is unavailable
                file_mtime_display=$(ls -ld "$file" 2>/dev/null | awk '{print $6 " " $7 " " $8}')
                file_mtime_iso=""
            fi
        else
            # Non-markdown file - use actual filename (with extension) as title
            title="$filename"
            # Compute file size (bytes) and human-readable size
            size_bytes=$(wc -c < "$file" 2>/dev/null | awk '{print $1}')
            [ -z "$size_bytes" ] && size_bytes=0
            size_human=$(awk -v s="$size_bytes" 'BEGIN{split("B KB MB GB TB PB",u);i=1;v=s+0;while(v>=1024 && i<6){v/=1024;i++} if (i==1) printf "%d %s", v,u[i]; else printf "%.1f %s", v,u[i]}')
            # Get last modified time (ISO and display)
            file_mtime_iso=$(date -r "$file" "+%Y-%m-%dT%H:%M:%S%z" 2>/dev/null || true)
            file_mtime_display=$(date -r "$file" "+%Y-%m-%d %H:%M" 2>/dev/null || true)
            if [ -z "$file_mtime_display" ]; then
                # Fallback using ls if date -r is unavailable
                file_mtime_display=$(ls -ld "$file" 2>/dev/null | awk '{print $6 " " $7 " " $8}')
                file_mtime_iso=""
            fi
            # Get file icon based on extension
            ext="${filename##*.}"
            [ "$ext" = "$filename" ] && ext="" # No extension
            ext_lower=$(echo "$ext" | tr '[:upper:]' '[:lower:]')
            file_icon=$(get_file_icon "$ext_lower")
            
            # Apply icon setting: auto=show for non-md, true=show for all, false=hide for all
            if [ "$icon" = "false" ]; then
                desc="${size_human} (${size_bytes} bytes)"
            else
                desc="${file_icon} ${size_human} (${size_bytes} bytes)"
            fi
            
            # Generate relative URL (use file as-is)
            url=$(echo "$file" | sed -e "s|^${src_dir}/||")
        fi
        
        # Output post entry
        printf '<article class="post-entry">\n'
        printf '<h3><a href="/%s">%s</a></h3>\n' "$url" "$title"
        
        # Handle date display based on date_opt parameter
        if [ "${file%.md}" != "$file" ]; then
            # Markdown file
            if [ "$date_opt" = "true" ]; then
                # Show date: prefer filename date, fallback to file mtime
                if [ -n "$date" ]; then
                    printf '<time datetime="%s">%s</time>\n' "$date" "$date"
                elif [ -n "$file_mtime_display" ]; then
                    if [ -n "$file_mtime_iso" ]; then
                        printf '<time datetime="%s">%s</time>\n' "$file_mtime_iso" "$file_mtime_display"
                    else
                        printf '<time datetime="%s">%s</time>\n' "$file_mtime_display" "$file_mtime_display"
                    fi
                fi
            elif [ "$date_opt" = "auto" ]; then
                # Auto: don't show date for markdown files (default behavior)
                :
            fi
        else
            # Non-markdown file: show file modification time
            if [ "$date_opt" != "false" ] && [ -n "$file_mtime_display" ]; then
                # Show for auto or true, hide for false
                if [ -n "$file_mtime_iso" ]; then
                    printf '<time datetime="%s">%s</time>\n' "$file_mtime_iso" "$file_mtime_display"
                else
                    printf '<time datetime="%s">%s</time>\n' "$file_mtime_display" "$file_mtime_display"
                fi
            fi
        fi
        
        # Handle description and icon display
        if [ -n "$desc" ]; then
            # For markdown files with icon=true, prepend a document icon
            if [ "${file%.md}" != "$file" ] && [ "$icon" = "true" ]; then
                # Add document icon for markdown files
                doc_icon='<svg class="file-icon" viewBox="0 0 16 16" width="14" height="14" aria-hidden="true"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg>'
                printf '<p>%s %s</p>\n' "$doc_icon" "$desc"
            else
                printf '<p>%s</p>\n' "$desc"
            fi
        fi
        
        printf '</article>\n'
    done
    
    # Generate pagination for static HTML
    if [ $total -gt $per_page ]; then
        printf '<nav class="pagination">\n'
        
        # Determine the link prefix based on current_file
        local link_prefix=""
        if echo "$current_file" | grep -q '/'; then
            # Already in subdirectory (e.g., "blog-example_/1_2.html")
            link_prefix=$(echo "$current_file" | sed 's|/[^/]*$|/|')
        else
            # Main file (e.g., "blog-example.html"), compute pagination directory name
            local base_name=$(echo "$current_file" | sed 's|\.html$||')
            local pagination_dirname=$(get_pagination_dirname "" "$base_name" "$custom_dir")
            link_prefix="${pagination_dirname}/"
        fi
        
        if [ $page -gt 1 ]; then
            if [ $page -eq 2 ]; then
                # Link to first page
                printf '<a href="/%s%d_1.html#§l%d" class="prev">%s</a>\n' "$link_prefix" "$list_id" "$list_id" "$display_prev"
            else
                # Link to previous page
                printf '<a href="/%s%d_%d.html#§l%d" class="prev">%s</a>\n' "$link_prefix" "$list_id" $((page - 1)) "$list_id" "$display_prev"
            fi
        fi
        
        printf '<span class="page-info">List %d - Page %d of %d</span>\n' "$list_id" "$page" "$total_pages"
        
        if [ $page -lt $total_pages ]; then
            printf '<a href="/%s%d_%d.html#§l%d" class="next">%s</a>\n' "$link_prefix" "$list_id" $((page + 1)) "$list_id" "$display_next"
        fi
        
        printf '</nav>\n'
    fi
    
    printf '</div>\n'
}

generate_paginated_directory() {
    # Generate paginated pages in a dedicated directory for files with list directives
    # $1 = source file, $2 = output directory, $3 = base filename (without extension)
    local src_file="$1"
    local dst_dir="$2"
    local base_name="$3"
    
    # Check if file has list directives (old or new syntax)
    local list_count=$(grep -c '<!---list' "$src_file" 2>/dev/null)
    
    # If grep fails or returns non-numeric, set to 0
    [ -z "$list_count" ] && list_count=0
    case "$list_count" in
        ''|*[!0-9]*) list_count=0 ;;
    esac
    
    # Skip if no list directive
    [ "$list_count" -eq 0 ] && return
    
    # Parse all list directives to find which ones need pagination
    local list_directives="$(mktemp)"
    # Extract list directives using AWK (YAML-like syntax)
    awk '/<!---list$/{p="";pp=999;cd="";ic="auto";dt="auto";dn="Next →";dp="← Previous";while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*pattern:[[:space:]]*(.+)$/,a)){p=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",p)}else if(match($0,/^[[:space:]]*per_page:[[:space:]]*([0-9]+)$/,a)){pp=a[1]}else if(match($0,/^[[:space:]]*custom_dir:[[:space:]]*(.+)$/,a)){cd=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",cd)}else if(match($0,/^[[:space:]]*icon:[[:space:]]*(.+)$/,a)){ic=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",ic)}else if(match($0,/^[[:space:]]*date:[[:space:]]*(.+)$/,a)){dt=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dt)}else if(match($0,/^[[:space:]]*display_next:[[:space:]]*(.+)$/,a)){dn=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dn);gsub(/^"|"$/,"",dn);gsub(/^'\''|'\''$/,"",dn)}else if(match($0,/^[[:space:]]*display_prev:[[:space:]]*(.+)$/,a)){dp=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dp);gsub(/^"|"$/,"",dp);gsub(/^'\''|'\''$/,"",dp)}}if(p!="")print p"|"pp"|"cd"|"ic"|"dt"|"dn"|"dp}' "$src_file" > "$list_directives"
    
    # Check if any list needs pagination (has per_page specified and > files)
    local needs_pagination=0
    local list_num=1
    
    while IFS='|' read -r pattern per_page list_custom_dir icon date_opt display_next display_prev; do
        local total_files
        
        # Count total matching files
        if echo "$pattern" | grep -q '/'; then
            total_files=$(find "${KVH_SRC}" -type f -path "*/${pattern}" 2>/dev/null | wc -l)
        else
            total_files=$(find "${KVH_SRC}" -maxdepth 1 -type f -name "${pattern}" 2>/dev/null | wc -l)
        fi
        
        if [ "$total_files" -gt "$per_page" ]; then
            needs_pagination=1
            break
        fi
        list_num=$((list_num + 1))
    done < "$list_directives"
    
    rm -f "$list_directives"
    
    # Skip if no pagination needed
    [ "$needs_pagination" -eq 0 ] && return
    
    # Parse list directives and generate pages
    local list_info="$(mktemp)"
    
    # Collect information about ALL lists (to preserve list IDs)
    local list_id=1
    awk '/<!---list$/{p="";pp=999;cd="";ic="auto";dt="auto";dn="Next →";dp="← Previous";while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*pattern:[[:space:]]*(.+)$/,a)){p=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",p)}else if(match($0,/^[[:space:]]*per_page:[[:space:]]*([0-9]+)$/,a)){pp=a[1]}else if(match($0,/^[[:space:]]*custom_dir:[[:space:]]*(.+)$/,a)){cd=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",cd)}else if(match($0,/^[[:space:]]*icon:[[:space:]]*(.+)$/,a)){ic=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",ic)}else if(match($0,/^[[:space:]]*date:[[:space:]]*(.+)$/,a)){dt=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dt)}else if(match($0,/^[[:space:]]*display_next:[[:space:]]*(.+)$/,a)){dn=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dn);gsub(/^"|"$/,"",dn);gsub(/^'\''|'\''$/,"",dn)}else if(match($0,/^[[:space:]]*display_prev:[[:space:]]*(.+)$/,a)){dp=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",dp);gsub(/^"|"$/,"",dp);gsub(/^'\''|'\''$/,"",dp)}}if(p!="")print p"|"pp"|"cd"|"ic"|"dt"|"dn"|"dp}' "$src_file" | while IFS='|' read -r pattern per_page list_custom_dir icon date_opt display_next display_prev; do
        local total_files total_pages
        
        # Count total matching files
        if echo "$pattern" | grep -q '/'; then
            total_files=$(find "${KVH_SRC}" -type f -path "*/${pattern}" 2>/dev/null | wc -l)
        else
            total_files=$(find "${KVH_SRC}" -maxdepth 1 -type f -name "${pattern}" 2>/dev/null | wc -l)
        fi
        
        if [ "$total_files" -gt 0 ]; then
            # Calculate number of pages needed
            total_pages=$(( ($total_files + $per_page - 1) / $per_page ))
            
            # Store: list_id|pattern|per_page|total_pages|custom_dir|icon|date|display_next|display_prev
            # Only store if pagination is needed (total_pages > 1)
            if [ "$total_pages" -gt 1 ]; then
                echo "${list_id}|${pattern}|${per_page}|${total_pages}|${list_custom_dir}|${icon}|${date_opt}|${display_next}|${display_prev}"
            fi
        fi
        # Increment list_id for ALL lists, not just those with pagination
        list_id=$((list_id + 1))
    done > "$list_info"
    
    # Generate all combinations of list pages
    while IFS='|' read -r lid pattern per_page total_pages list_custom_dir icon date_opt display_next display_prev; do
        # Determine pagination directory for THIS specific list
        local pagination_dirname=$(get_pagination_dirname "$src_file" "$base_name" "$list_custom_dir")
        local pagination_dir="${dst_dir}/${pagination_dirname}"
        mkdir -p "$pagination_dir"
        
        local page=1
        while [ $page -le $total_pages ]; do
            # Create a temporary markdown file with the page-specific directive
            local temp_md="$(mktemp)"
            local list_counter=1
            
            # Replace list directives with page-specific versions (convert YAML to internal format with all params)
            awk -v target_list="$lid" -v target_page="$page" -v list_count="$list_count" '
                BEGIN { current_list = 0 }
                /<!---list$/ {
                    current_list++
                    p="";pp=999;cd="";ic="auto";dt="auto";dn="Next →";dp="← Previous"
                    
                    # Read until closing --->
                    while (getline > 0) {
                        if ($0 ~ /^--->$/) break
                        if (match($0, /^[[:space:]]*pattern:[[:space:]]*(.+)$/, a)) {
                            p = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", p)
                        }
                        else if (match($0, /^[[:space:]]*per_page:[[:space:]]*([0-9]+)$/, a)) {
                            pp = a[1]
                        }
                        else if (match($0, /^[[:space:]]*custom_dir:[[:space:]]*(.+)$/, a)) {
                            cd = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", cd)
                        }
                        else if (match($0, /^[[:space:]]*icon:[[:space:]]*(.+)$/, a)) {
                            ic = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", ic)
                        }
                        else if (match($0, /^[[:space:]]*date:[[:space:]]*(.+)$/, a)) {
                            dt = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", dt)
                        }
                        else if (match($0, /^[[:space:]]*display_next:[[:space:]]*(.+)$/, a)) {
                            dn = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", dn)
                            gsub(/^"|"$/, "", dn)
                            gsub(/^'\''|'\''$/, "", dn)
                        }
                        else if (match($0, /^[[:space:]]*display_prev:[[:space:]]*(.+)$/, a)) {
                            dp = a[1]
                            gsub(/^[[:space:]]+|[[:space:]]+$/, "", dp)
                            gsub(/^"|"$/, "", dp)
                            gsub(/^'\''|'\''$/, "", dp)
                        }
                    }
                    
                    # Output internal format (9 fields) that process_blog_lists understands
                    if (p != "") {
                        if (current_list == target_list) {
                            # This is the list we want to paginate
                            if (cd != "") {
                                print "<!---list:" p ":" pp ":" target_page ":" current_list ":" cd ":" ic ":" dt ":" dn ":" dp "--->"
                            } else {
                                print "<!---list:" p ":" pp ":" target_page ":" current_list "::" ic ":" dt ":" dn ":" dp "--->"
                            }
                        } else {
                            # Other lists show page 1
                            if (cd != "") {
                                print "<!---list:" p ":" pp ":1:" current_list ":" cd ":" ic ":" dt ":" dn ":" dp "--->"
                            } else {
                                print "<!---list:" p ":" pp ":1:" current_list "::" ic ":" dt ":" dn ":" dp "--->"
                            }
                        }
                    }
                    next
                }
                { print }
            ' "$src_file" > "$temp_md"
            
            # Generate the HTML for this page
            local page_file="${lid}_${page}.html"
            local processed="$(mktemp)"
            
            process_blog_lists "$temp_md" "${pagination_dirname}/${page_file}" > "$processed"
            
            # Extract metadata
            local page_icon=$(getvalue "$src_file" "icon")
            local page_title=$(getvalue "$src_file" "title")
            local page_desc=$(getvalue "$src_file" "description")
            
            [ "$page_icon" ] || page_icon="${KVH_PAGE_ICON}"
            [ "$page_title" ] || page_title="${KVH_PAGE_NAME}"
            [ "$page_desc" ] || page_desc="${KVH_PAGE_DESC}"
            
            # Add list and page info to title
            if [ "$list_count" -gt 1 ]; then
                page_title="${page_title} - List ${lid} Page ${page}"
            else
                page_title="${page_title} - Page ${page}"
            fi
            
            # Escape for sed
            page_icon="$(printf '%s' "${page_icon}" | sed 's/[&\|]/\\&/g')"
            page_title="$(printf '%s' "${page_title}" | sed 's/[&\|]/\\&/g')"
            page_desc="$(printf '%s' "${page_desc}" | sed 's/[&\|]/\\&/g')"
            
            # Resolve header/footer for the source file's directory
            local SRC_DIR_ABS="$(cd "$(dirname "$src_file")" 2>/dev/null && pwd)"
            local HDR_HTML_PG="$(get_header_html "$SRC_DIR_ABS")"
            local FTR_HTML_PG="$(get_footer_html "$SRC_DIR_ABS")"
            [ -n "$HDR_HTML_PG" ] && HDR_HTML_PG="<header>${HDR_HTML_PG}</header>"
            [ -n "$FTR_HTML_PG" ] && FTR_HTML_PG="<footer>${FTR_HTML_PG}</footer>"

            # Generate HTML
            printf "%s\n" \
                "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '/PAGE_DATA/,//d')" \
                "${HDR_HTML_PG}" \
                "$(md2html "${processed}")" \
                "${FTR_HTML_PG}" \
                "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '0,/%PAGE_DATA%/d')" \
            | sed   -e "s|%PAGE_TITLE%|${page_title}|g" \
                    -e "s|%PAGE_DESC%|${page_desc}|g" \
                    -e "s|%PAGE_ICON%|${page_icon}|g" \
                    -e "s|%KVH_VERSION%|${KVH_VERSION}|g" \
            | minify_html \
            > "${pagination_dir}/${page_file}"
            
            rm -f "$temp_md" "$processed"
            page=$((page + 1))
        done
    done < "$list_info"
    
    rm -f "$list_info"
}

process_blog_lists() {
    # Process list directives and generate HTML
    # $1 = input file, $2 = current output file (for pagination links), $3 = current list id (optional), $4 = total lists (optional)
    local input="$1"
    local current_file="$2"
    local current_list_id="${3:-0}"
    local total_lists="${4:-1}"
    local temp="$(mktemp)"
    
    # Count total list directives if not provided
    if [ "$current_list_id" -eq 0 ]; then
        total_lists=$(grep -c '<!---list' "$input" 2>/dev/null)
        [ -z "$total_lists" ] && total_lists=0
        case "$total_lists" in
            ''|*[!0-9]*) total_lists=0 ;;
        esac
        [ "$total_lists" -eq 0 ] && total_lists=1
    fi
    
    # Convert list directives to __KVHLIST__ placeholders (handles both YAML and internal formats)
    awk '/<!---list$/ {
        # YAML format
        p="";pp=999;cd="";ic="auto";dt="auto";dn="Next →";dp="← Previous"
        while (getline > 0) {
            if ($0 ~ /^--->$/) break
            if (match($0, /^[[:space:]]*pattern:[[:space:]]*(.+)$/, arr)) {
                p = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", p)
            }
            else if (match($0, /^[[:space:]]*per_page:[[:space:]]*([0-9]+)$/, arr)) {
                pp = arr[1]
            }
            else if (match($0, /^[[:space:]]*custom_dir:[[:space:]]*(.+)$/, arr)) {
                cd = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", cd)
            }
            else if (match($0, /^[[:space:]]*icon:[[:space:]]*(.+)$/, arr)) {
                ic = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", ic)
            }
            else if (match($0, /^[[:space:]]*date:[[:space:]]*(.+)$/, arr)) {
                dt = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", dt)
            }
            else if (match($0, /^[[:space:]]*display_next:[[:space:]]*(.+)$/, arr)) {
                dn = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", dn)
                gsub(/^"|"$/, "", dn)
                gsub(/^'\''|'\''$/, "", dn)
            }
            else if (match($0, /^[[:space:]]*display_prev:[[:space:]]*(.+)$/, arr)) {
                dp = arr[1]
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", dp)
                gsub(/^"|"$/, "", dp)
                gsub(/^'\''|'\''$/, "", dp)
            }
        }
        if (p != "") {
            if (cd != "") {
                print "__KVHLIST__" p "__" pp "__1__0__" cd "__" ic "__" dt "__" dn "__" dp "__"
            } else {
                print "__KVHLIST__" p "__" pp "__1__0____" ic "__" dt "__" dn "__" dp "__"
            }
        }
        next
    }
    /<!---list:/ {
        # Internal colon format (from pagination) - now with 9 fields: pattern:per_page:page:list_id:custom_dir:icon:date:display_next:display_prev
        line = $0
        if (match(line, /<!---list:([^:]+):([0-9]+):([0-9]+):([0-9]+):([^:]*):([^:]*):([^:]*):([^:]*):([^-]+)--->/)) {
            split(substr(line, RSTART+10, RLENGTH-14), parts, ":")
            print "__KVHLIST__" parts[1] "__" parts[2] "__" parts[3] "__" parts[4] "__" parts[5] "__" parts[6] "__" parts[7] "__" parts[8] "__" parts[9] "__"
        } else if (match(line, /<!---list:([^:]+):([0-9]+):([0-9]+):([0-9]+)--->/)) {
            # Legacy format without extra params - use defaults
            split(substr(line, RSTART+10, RLENGTH-14), parts, ":")
            print "__KVHLIST__" parts[1] "__" parts[2] "__" parts[3] "__" parts[4] "____auto__auto__Next →__← Previous__"
        } else if (match(line, /<!---list:([^:]+):([0-9]+):([0-9]+):([0-9]+):([^-]+)--->/)) {
            # Legacy format with custom_dir but no extra params
            split(substr(line, RSTART+10, RLENGTH-14), parts, ":")
            print "__KVHLIST__" parts[1] "__" parts[2] "__" parts[3] "__" parts[4] "__" parts[5] "__auto__auto__Next →__← Previous__"
        }
        next
    }
    { print }' "$input" > "$temp"
    
    # Replace placeholders with auto-incrementing list_id
    local auto_list_id=1
    while IFS= read -r line; do
        if echo "$line" | grep -q '^__KVHLIST__'; then
            # Parse the extended format with 9 fields
            pattern=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\1/')
            per_page=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\2/')
            page_num=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\3/')
            list_id=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\4/')
            list_custom_dir=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\5/')
            icon=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\6/')
            date_opt=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\7/')
            display_next=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\8/')
            display_prev=$(echo "$line" | sed 's/__KVHLIST__\([^_]*\)__\([0-9]*\)__\([0-9]*\)__\([0-9]*\)__\([^_]*\)__\([^_]*\)__\([^_]*\)__\(.*\)__\(.*\)__/\9/')
            
            # Use provided list_id if specified (non-zero), otherwise auto-assign
            if [ "$current_list_id" -gt 0 ]; then
                list_id="$current_list_id"
            elif [ "$list_id" -eq 0 ]; then
                list_id="$auto_list_id"
                auto_list_id=$((auto_list_id + 1))
            fi
            
            # Use the list-specific custom_dir from the directive
            generate_post_list "${KVH_SRC}" "$pattern" "$page_num" "$per_page" "$current_file" "$list_id" "$total_lists" "$list_custom_dir" "$icon" "$date_opt" "$display_next" "$display_prev"
        else
            echo "$line"
        fi
    done < "$temp"
    
    rm -f "$temp"
}

md2html() {
    # Pre-scan to extract all footnote numbers and reserve their IDs
    local reserved_ids=""
    reserved_ids=$(grep -o '\[\^[0-9]\+\]' "$1" 2>/dev/null | sed 's/\[\^\([0-9]\+\)\]/fn\1 fnref\1 /g' | tr ' ' '\n' | sort -u | tr '\n' ' ')
    
    # Count list directives and reserve list IDs
    local list_count=$(process_lists "$1" | grep -c '^__KVHLIST__' 2>/dev/null)
    # Handle empty/error case
    case "$list_count" in
        ''|*[!0-9]*) list_count=0 ;;
    esac
    local i=1
    while [ "$i" -le "$list_count" ]; do
        reserved_ids="${reserved_ids}§l${i} "
        i=$((i + 1))
    done
    
    # Remove KVH metadata comments and parse markdown to HTML using pure POSIX shell
    sed -e '/<!---/,/--->/d' -e '/<!---/,/-->/{/^[[:space:]]*$/d;}' "$1" | awk -v reserved_ids="${reserved_ids}" '
    BEGIN {
        in_code_block = 0
        in_html_block = 0
        in_table = 0
        buffer = ""
        line_count = 0
        # Stack-based list management
        list_depth = 0
        for (i = 0; i < 100; i++) {
            list_type[i] = ""
            list_indent[i] = -1
        }
        # Footnote storage
        footnote_count = 0
        # Definition list tracking
        in_dl = 0
        # Heading ID tracking to prevent duplicates
        for (i = 0; i < 1000; i++) {
            heading_ids[i] = ""
        }
        heading_id_count = 0
        # Load reserved IDs (footnotes, lists) passed from shell
        split(reserved_ids, reserved_array, " ")
        for (i in reserved_array) {
            if (reserved_array[i] != "") {
                heading_ids[heading_id_count] = reserved_array[i]
                heading_id_count++
            }
        }
    }

    function escape_html(text) {
        gsub(/&/, "\\&amp;", text)
        gsub(/</, "\\&lt;", text)
        gsub(/>/, "\\&gt;", text)
        gsub(/"/, "\\&quot;", text)
        return text
    }

    function process_inline_formatting(text,    protected_count, code_count, i, code, placeholder, protected_text, tag_match, pos, escaped_count, footnote_count_local, fn_num, fn_html) {
        # Handle escaped characters first - protect them from markdown processing
        escaped_count = 0
        while (match(text, /\\[\\`*_{}\[\]()#+.!|~^=-]/)) {
            escaped_char = substr(text, RSTART+1, 1)
            placeholder = "§§KVHESCAPED" escaped_count "§§"
            escaped_protected[escaped_count] = escaped_char
            text = substr(text, 1, RSTART-1) placeholder substr(text, RSTART+RLENGTH)
            escaped_count++
        }

        # Protect existing HTML tags (like <pre>, <div>, etc)
        protected_count = 0
        while (match(text, /<[a-zA-Z\/][^>]*>/)) {
            protected_text = substr(text, RSTART, RLENGTH)
            placeholder = "§§KVHPROTECTED" protected_count "§§"
            protected[protected_count] = protected_text
            text = substr(text, 1, RSTART-1) placeholder substr(text, RSTART+RLENGTH)
            protected_count++
        }

        # Process footnote references [^1] early to avoid conflicts
        footnote_count_local = 0
        while (match(text, /\[\^[0-9]+\]/)) {
            fn_num = substr(text, RSTART+2, RLENGTH-3)
            placeholder = "§§KVHFOOTNOTE" footnote_count_local "§§"
            footnote_protected[footnote_count_local] = "<sup><a href=\"#fn" fn_num "\" id=\"fnref" fn_num "\">[" fn_num "]</a></sup>"
            text = substr(text, 1, RSTART-1) placeholder substr(text, RSTART+RLENGTH)
            footnote_count_local++
        }

        # Process code spans and protect them from further formatting
        code_count = 0
        while (match(text, /`[^`]+`/)) {
            code = substr(text, RSTART+1, RLENGTH-2)
            placeholder = "§§KVHCODE" code_count "§§"
            code_protected[code_count] = "<code>" escape_html(code) "</code>"
            text = substr(text, 1, RSTART-1) placeholder substr(text, RSTART+RLENGTH)
            code_count++
        }

        # Process highlight (==text==)
        while (match(text, /==[^=]+==/)) {
            highlight = substr(text, RSTART+2, RLENGTH-4)
            highlight_html = "<mark>" highlight "</mark>"
            text = substr(text, 1, RSTART-1) highlight_html substr(text, RSTART+RLENGTH)
        }

        # Process bold (**text** and __text__)
        while (match(text, /\*\*[^*]+\*\*/)) {
            bold = substr(text, RSTART+2, RLENGTH-4)
            bold_html = "<strong>" bold "</strong>"
            text = substr(text, 1, RSTART-1) bold_html substr(text, RSTART+RLENGTH)
        }
        while (match(text, /__[^_]+__/)) {
            bold = substr(text, RSTART+2, RLENGTH-4)
            bold_html = "<strong>" bold "</strong>"
            text = substr(text, 1, RSTART-1) bold_html substr(text, RSTART+RLENGTH)
        }

        # Process italic (*text* and _text_)
        while (match(text, /\*[^*]+\*/)) {
            italic = substr(text, RSTART+1, RLENGTH-2)
            italic_html = "<em>" italic "</em>"
            text = substr(text, 1, RSTART-1) italic_html substr(text, RSTART+RLENGTH)
        }
        while (match(text, /_[^_]+_/)) {
            italic = substr(text, RSTART+1, RLENGTH-2)
            italic_html = "<em>" italic "</em>"
            text = substr(text, 1, RSTART-1) italic_html substr(text, RSTART+RLENGTH)
        }

        # Process strikethrough (~~text~~)
        while (match(text, /~~[^~]+~~/)) {
            strike = substr(text, RSTART+2, RLENGTH-4)
            strike_html = "<del>" strike "</del>"
            text = substr(text, 1, RSTART-1) strike_html substr(text, RSTART+RLENGTH)
        }

        # Process subscript (H~2~O)
        while (match(text, /~[^~]+~/)) {
            sub_text = substr(text, RSTART+1, RLENGTH-2)
            sub_html = "<sub>" sub_text "</sub>"
            text = substr(text, 1, RSTART-1) sub_html substr(text, RSTART+RLENGTH)
        }

        # Process superscript (X^2^)
        while (match(text, /\^[^^]+\^/)) {
            sup_text = substr(text, RSTART+1, RLENGTH-2)
            sup_html = "<sup>" sup_text "</sup>"
            text = substr(text, 1, RSTART-1) sup_html substr(text, RSTART+RLENGTH)
        }

        # Process images ![alt](src) - MUST come before links
        while (match(text, /!\[[^\]]*\]\([^)]*\)/)) {
            # Skip the leading ! and [ to get just the content
            img_match = substr(text, RSTART+2, RLENGTH-3)
            split_pos = index(img_match, "](")
            if (split_pos > 0) {
                alt_text = substr(img_match, 1, split_pos-1)
                src_url = substr(img_match, split_pos+2)
                img_html = "<img alt=\"" escape_html(alt_text) "\" src=\"" escape_html(src_url) "\" />"
                text = substr(text, 1, RSTART-1) img_html substr(text, RSTART+RLENGTH)
            }
        }

        # Process links [text](url)
        while (match(text, /\[[^\]]*\]\([^)]*\)/)) {
            link_text = substr(text, RSTART+1, RLENGTH-2)
            split_pos = index(link_text, "](")
            if (split_pos > 0) {
                text_part = substr(link_text, 1, split_pos-1)
                url_part = substr(link_text, split_pos+2)
                link_html = "<a href=\"" escape_html(url_part) "\">" text_part "</a>"
                text = substr(text, 1, RSTART-1) link_html substr(text, RSTART+RLENGTH)
            }
        }

        # Process line breaks (two or more spaces at end of line)
        if (match(text, /  +$/)) {
            text = substr(text, 1, RSTART-1) "<br />"
        }

        # Restore footnotes
        for (i = footnote_count_local - 1; i >= 0; i--) {
            placeholder = "§§KVHFOOTNOTE" i "§§"
            while ((pos = index(text, placeholder)) > 0) {
                text = substr(text, 1, pos - 1) footnote_protected[i] substr(text, pos + length(placeholder))
            }
        }

        # Restore code spans using manual replacement to avoid gsub issues with special chars
        for (i = code_count - 1; i >= 0; i--) {
            placeholder = "§§KVHCODE" i "§§"
            while ((pos = index(text, placeholder)) > 0) {
                text = substr(text, 1, pos - 1) code_protected[i] substr(text, pos + length(placeholder))
            }
        }

        # Restore protected HTML tags
        for (i = protected_count - 1; i >= 0; i--) {
            placeholder = "§§KVHPROTECTED" i "§§"
            while ((pos = index(text, placeholder)) > 0) {
                text = substr(text, 1, pos - 1) protected[i] substr(text, pos + length(placeholder))
            }
        }

        # Restore escaped characters last
        for (i = escaped_count - 1; i >= 0; i--) {
            placeholder = "§§KVHESCAPED" i "§§"
            while ((pos = index(text, placeholder)) > 0) {
                text = substr(text, 1, pos - 1) escaped_protected[i] substr(text, pos + length(placeholder))
            }
        }

        return text
    }

    function process_table_row(line) {
        # Split table row by | and create table cells
        gsub(/^\s*\|\s*/, "", line)
        gsub(/\s*\|\s*$/, "", line)

        result = "<tr>"
        n = split(line, cells, /\s*\|\s*/)
        for (i = 1; i <= n; i++) {
            cell = cells[i]
            # Check if it is a header separator row
            if (cell ~ /^:?-+:?$/) {
                return ""
            }
            # Clean up cell content
            gsub(/^[[:space:]]+|[[:space:]]+$/, "", cell)
            result = result "<td>" process_inline_formatting(cell) "</td>"
        }
        result = result "</tr>"
        return result
    }

    function close_lists_to_depth(target_depth) {
        while (list_depth > target_depth) {
            print "</li></" list_type[list_depth] ">"
            list_type[list_depth] = ""
            list_indent[list_depth] = -1
            list_depth--
        }
    }

    function close_all_lists() {
        close_lists_to_depth(0)
    }

    {
        line = $0
        line_count++

        # Handle code blocks (fenced with ``` or indented) - MUST come first
        if (line ~ /^```/) {
            if (in_code_block) {
                print "</pre></div>"
                in_code_block = 0
                buffer = ""
            } else {
                close_all_lists()
                if (in_dl) {
                    print "</dl>"
                    in_dl = 0
                }
                if (buffer != "") {
                    print "<p>" process_inline_formatting(buffer) "</p>"
                    buffer = ""
                }
                # Extract language if specified
                lang = substr(line, 4)
                gsub(/^[[:space:]]+|[[:space:]]+$/, "", lang)
                if (lang != "") {
                    print "<div class=\"code-block\" data-lang=\"" lang "\"><pre>"
                } else {
                    print "<div class=\"code-block\"><pre>"
                }
                in_code_block = 1
            }
            next
        }

        if (in_code_block) {
            print escape_html(line)
            next
        }

        # Handle footnote definitions [^1]: text
        if (match(line, /^\[\^[0-9]+\]:/)) {
            close_all_lists()
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            match(line, /^\[\^[0-9]+\]:/)
            fn_num = substr(line, 3, RLENGTH-4)
            fn_text = substr(line, RLENGTH+2)
            gsub(/^[[:space:]]+/, "", fn_text)
            footnotes[fn_num] = fn_text
            footnote_count++
            next
        }

        # Handle HTML blocks (pass through as-is)
        if (line ~ /^<[^>]+>.*<\/[^>]+>$/ || line ~ /^<[^>]+\/>$/) {
            close_all_lists()
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            print line
            next
        }

        # Handle horizontal rules
        if (line ~ /^(\*{3,}|-{3,}|_{3,})\s*$/) {
            close_all_lists()
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            print "<hr />"
            next
        }

        # Handle headings with optional custom IDs (# Heading or # Heading {#custom-id})
        if (match(line, /^(#{1,6})\s+(.*)/)) {
            close_all_lists()
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            match(line, /^(#{1,6})/)
            level = RLENGTH
            heading_text = substr(line, RSTART + level + 1)
            gsub(/^[[:space:]]+/, "", heading_text)
            
            # Check for custom ID {#custom-id}
            custom_id = ""
            if (match(heading_text, /\{#[^}]+\}$/)) {
                custom_id = substr(heading_text, RSTART+2, RLENGTH-3)
                heading_text = substr(heading_text, 1, RSTART-1)
                gsub(/[[:space:]]+$/, "", heading_text)
            } else {
                # Generate automatic ID from heading text
                custom_id = tolower(heading_text)
                # Remove markdown formatting for ID generation
                gsub(/[*_~`\[\](){}]/, "", custom_id)
                # Replace spaces and special chars with hyphens
                gsub(/[^a-z0-9]+/, "-", custom_id)
                # Remove leading/trailing hyphens
                gsub(/^-+|-+$/, "", custom_id)
            }
            
            # Check for duplicate IDs and append number if needed
            if (custom_id != "") {
                base_id = custom_id
                id_suffix = 2
                is_duplicate = 0
                
                # Check if ID already exists
                for (j = 0; j < heading_id_count; j++) {
                    if (heading_ids[j] == custom_id) {
                        is_duplicate = 1
                        break
                    }
                }
                
                # Keep incrementing suffix until we find unique ID
                while (is_duplicate) {
                    custom_id = base_id "-" id_suffix
                    id_suffix++
                    is_duplicate = 0
                    for (j = 0; j < heading_id_count; j++) {
                        if (heading_ids[j] == custom_id) {
                            is_duplicate = 1
                            break
                        }
                    }
                }
                
                # Store this ID
                heading_ids[heading_id_count] = custom_id
                heading_id_count++
                
                print "<h" level " id=\"" custom_id "\" class=\"heading-with-anchor\">" process_inline_formatting(heading_text) "<a href=\"#" custom_id "\" class=\"heading-anchor\" aria-label=\"Permalink\"><svg class=\"octicon\" viewBox=\"0 0 16 16\" width=\"16\" height=\"16\" aria-hidden=\"true\"><path d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"></path></svg></a></h" level ">"
            } else {
                print "<h" level ">" process_inline_formatting(heading_text) "</h" level ">"
            }
            next
        }

        # Handle blockquotes (> at start)
        if (line ~ /^>\s*/) {
            close_all_lists()
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            gsub(/^>\s*/, "", line)
            print "<blockquote>" process_inline_formatting(line) "</blockquote>"
            next
        }

        # Handle tables - must start and end with | for proper table syntax
        if (line ~ /^\s*\|.*\|\s*$/) {
            close_all_lists()
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            if (!in_table) {
                print "<table>"
                in_table = 1
            }
            table_row = process_table_row(line)
            if (table_row != "") {
                print table_row
            }
            next
        } else if (in_table) {
            print "</table>"
            in_table = 0
        }

        # Handle definition lists (term on one line, : definition on next)
        # Dont trigger for list items
        if (line ~ /^[^ \t]/ && line !~ /^[[:space:]]*$/ && line !~ /:/ && line !~ /^[-*+]\s/ && line !~ /^[0-9]+\.\s/ && getline next_line > 0) {
            if (next_line ~ /^:[[:space:]]/) {
                close_all_lists()
                if (buffer != "") {
                    print "<p>" process_inline_formatting(buffer) "</p>"
                    buffer = ""
                }
                if (!in_dl) {
                    print "<dl>"
                    in_dl = 1
                }
                print "<dt>" process_inline_formatting(line) "</dt>"
                gsub(/^:[[:space:]]*/, "", next_line)
                print "<dd>" process_inline_formatting(next_line) "</dd>"
                next
            } else {
                # Put the line back into processing
                line = line "\n" next_line
            }
        }

        # Handle task lists - [x] or [ ]
        is_task = line ~ /^[ \t]*[-*+]\s+\[([ xX])\]\s+/
        
        if (is_task) {
            # Get indent level
            match(line, /^[ \t]*/)
            indent = RLENGTH
            
            # Extract checkbox state
            match(line, /\[([ xX])\]/)
            checked = (substr(line, RSTART+1, 1) ~ /[xX]/) ? "checked" : ""
            
            # Remove list marker and checkbox
            gsub(/^[ \t]*[-*+]\s+\[([ xX])\]\s+/, "", line)
            content = line
            ltype = "ul"
            
            # Find target depth based on indentation
            target_depth = 0
            for (i = 1; i <= list_depth; i++) {
                if (indent > list_indent[i]) {
                    target_depth = i
                }
            }
            
            # Start or continue list
            if (list_depth > 0 && indent > list_indent[list_depth]) {
                list_depth++
                list_type[list_depth] = ltype
                list_indent[list_depth] = indent
                print "<" ltype " class=\"task-list\">"
                print "<li class=\"task-list-item\"><input type=\"checkbox\" disabled " checked " /> " process_inline_formatting(content)
            } else if (list_depth > 0 && indent <= list_indent[list_depth]) {
                while (list_depth > 0 && indent < list_indent[list_depth]) {
                    print "</li></" list_type[list_depth] ">"
                    list_type[list_depth] = ""
                    list_indent[list_depth] = -1
                    list_depth--
                }
                if (list_depth > 0 && indent == list_indent[list_depth]) {
                    print "</li>"
                    print "<li class=\"task-list-item\"><input type=\"checkbox\" disabled " checked " /> " process_inline_formatting(content)
                } else {
                    list_depth++
                    list_type[list_depth] = ltype
                    list_indent[list_depth] = indent
                    print "<" ltype " class=\"task-list\">"
                    print "<li class=\"task-list-item\"><input type=\"checkbox\" disabled " checked " /> " process_inline_formatting(content)
                }
            } else {
                if (in_dl) {
                    print "</dl>"
                    in_dl = 0
                }
                if (buffer != "") {
                    print "<p>" process_inline_formatting(buffer) "</p>"
                    buffer = ""
                }
                list_depth = 1
                list_type[1] = ltype
                list_indent[1] = indent
                print "<" ltype " class=\"task-list\">"
                print "<li class=\"task-list-item\"><input type=\"checkbox\" disabled " checked " /> " process_inline_formatting(content)
            }
            next
        }

        # Handle regular lists with proper nesting
        is_ul = line ~ /^[ \t]*[-*+]\s+/
        is_ol = line ~ /^[ \t]*[0-9]+\.\s+/
        
        if (is_ul || is_ol) {
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            # Get indent level and content
            match(line, /^[ \t]*/)
            indent = RLENGTH
            
            # Determine list type
            if (is_ul) {
                gsub(/^[ \t]*[-*+]\s+/, "", line)
                ltype = "ul"
            } else {
                gsub(/^[ \t]*[0-9]+\.\s+/, "", line)
                ltype = "ol"
            }
            
            content = line
            
            # Find target depth based on indentation
            target_depth = 0
            for (i = 1; i <= list_depth; i++) {
                if (indent > list_indent[i]) {
                    target_depth = i
                }
            }
            
            # If this is more indented than current, its nested
            if (list_depth > 0 && indent > list_indent[list_depth]) {
                # Start nested list
                list_depth++
                list_type[list_depth] = ltype
                list_indent[list_depth] = indent
                print "<" ltype ">"
                print "<li>" process_inline_formatting(content)
            }
            # If same or less indented, close lists as needed
            else if (list_depth > 0 && indent <= list_indent[list_depth]) {
                # Close lists until we find matching indent or go to root
                while (list_depth > 0 && indent < list_indent[list_depth]) {
                    print "</li></" list_type[list_depth] ">"
                    list_type[list_depth] = ""
                    list_indent[list_depth] = -1
                    list_depth--
                }
                
                # If we found matching indent with different type, close and reopen
                if (list_depth > 0 && indent == list_indent[list_depth] && ltype != list_type[list_depth]) {
                    print "</li></" list_type[list_depth] ">"
                    list_type[list_depth] = ""
                    list_indent[list_depth] = -1
                    list_depth--
                }
                
                # If at same level, just new item
                if (list_depth > 0 && indent == list_indent[list_depth] && ltype == list_type[list_depth]) {
                    print "</li>"
                    print "<li>" process_inline_formatting(content)
                }
                # Otherwise start new list at this level
                else {
                    list_depth++
                    list_type[list_depth] = ltype
                    list_indent[list_depth] = indent
                    print "<" ltype ">"
                    print "<li>" process_inline_formatting(content)
                }
            }
            # First list item
            else {
                if (buffer != "") {
                    print "<p>" process_inline_formatting(buffer) "</p>"
                    buffer = ""
                }
                list_depth = 1
                list_type[1] = ltype
                list_indent[1] = indent
                print "<" ltype ">"
                print "<li>" process_inline_formatting(content)
            }
            next
        }
        
        # Handle indented continuation lines within list items
        if (list_depth > 0 && line ~ /^[ \t]+[^ \t]/) {
            # This is an indented line within a list - add as continuation content
            gsub(/^[ \t]+/, "", line)
            print process_inline_formatting(line)
            next
        }
        
        # Non-list line - close all lists
        if (list_depth > 0 && line !~ /^[ \t]*$/) {
            close_all_lists()
        }

        # Handle paragraphs (non-empty lines that are not special)
        if (line ~ /^[^ \t]/ && line != "") {
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
            }
            buffer = line
            next
        }

        # Handle empty lines (end paragraphs)
        if (line ~ /^[[:space:]]*$/) {
            if (in_dl) {
                print "</dl>"
                in_dl = 0
            }
            if (buffer != "") {
                print "<p>" process_inline_formatting(buffer) "</p>"
                buffer = ""
            }
            next
        }
    }

    END {
        # Clean up any remaining open tags
        if (in_code_block) print "</pre></div>"
        if (in_table) print "</table>"
        if (in_dl) print "</dl>"
        
        # Close any remaining lists
        close_all_lists()

        if (buffer != "") {
            print "<p>" process_inline_formatting(buffer) "</p>"
        }

        # Print footnotes at the end if any exist
        if (footnote_count > 0) {
            print "<div class=\"footnotes\">"
            print "<ol>"
            for (i = 1; i <= footnote_count; i++) {
                if (i in footnotes) {
                    print "<li id=\"fn" i "\">" process_inline_formatting(footnotes[i]) " <a href=\"#fnref" i "\">↩</a></li>"
                }
            }
            print "</ol>"
            print "</div>"
        }
    }'
}

minify_html() {
    awk '
    BEGIN { css_buffer = "" }
    /<style>/ { print; in_style=1; next }
    /<\/style>/ {
        if (css_buffer != "") {
            print css_buffer
            css_buffer = ""
        }
        print
        in_style=0
        next
    }
    in_style {
        # Remove comments
        gsub(/\/\*[^*]*\*+([^/*][^*]*\*+)*\//, "")
        # Remove leading/trailing whitespace
        gsub(/^[[:space:]]+|[[:space:]]+$/, "")
        # Skip empty lines
        if (length($0) == 0) next
        # Remove whitespace around { } : ; ,
        gsub(/[[:space:]]*\{[[:space:]]*/, "{")
        gsub(/[[:space:]]*\}[[:space:]]*/, "}")
        gsub(/[[:space:]]*:[[:space:]]*/, ":")
        gsub(/[[:space:]]*;[[:space:]]*/, ";")
        gsub(/[[:space:]]*,[[:space:]]*/, ",")
        # Concatenate to buffer
        css_buffer = css_buffer $0
        next
    }
    { print }
    '
}

# Hierarchical header/footer configuration
KVH_HDR_FILE="_header.md"
KVH_FTR_FILE="_footer.md"
KVH_HF_MAP=""
KVH_HF_CACHE_DIR=""

build_header_footer_map() {
    # Build map: dir -> (header_path, footer_path) using hierarchical resolution
    KVH_HF_MAP="$(mktemp)"
    KVH_HF_CACHE_DIR="$(mktemp -d)"
    local root="${KVH_SRC_ROOT}"
    [ -d "$root" ] || return
    
    # Process directories from shallow to deep so parents are computed before children
    find "$root" -type d | awk '{print length, $0}' | sort -n | cut -d' ' -f2- | while read -r dir; do
        local parent="$(dirname "$dir")"
        local header=""
        local footer=""
        
        # Check for _header.md in current dir
        if [ -f "$dir/$KVH_HDR_FILE" ]; then
            header="$dir/$KVH_HDR_FILE"
        else
            # Inherit from parent
            header="$(awk -F '\t' -v p="$parent" '($1==p){print $2; exit}' "$KVH_HF_MAP")"
        fi
        
        # Check for _footer.md in current dir
        if [ -f "$dir/$KVH_FTR_FILE" ]; then
            footer="$dir/$KVH_FTR_FILE"
        else
            # Inherit from parent
            footer="$(awk -F '\t' -v p="$parent" '($1==p){print $3; exit}' "$KVH_HF_MAP")"
        fi
        
        printf "%s\t%s\t%s\n" "$dir" "$header" "$footer" >> "$KVH_HF_MAP"
    done
}

kvh_hf_cached_html() {
    # $1 = markdown file path; caches full HTML by path using cksum key
    local p="$1"
    [ -f "$p" ] || return
    local key cache_file
    key=$(printf '%s' "$p" | cksum | awk '{print $1"_"$2}')
    cache_file="${KVH_HF_CACHE_DIR}/${key}.html"
    if [ -f "$cache_file" ]; then
        cat "$cache_file"
        return
    fi
    md2html "$p" > "$cache_file"
    cat "$cache_file"
}

get_header_html() {
    # $1 = absolute directory of the file being processed
    local hdr_path
    hdr_path="$(awk -F '\t' -v d="$1" '($1==d){print $2; exit}' "$KVH_HF_MAP")"
    [ -n "$hdr_path" ] && [ -f "$hdr_path" ] || return
    kvh_hf_cached_html "$hdr_path"
}

get_footer_html() {
    # $1 = absolute directory of the file being processed
    local ftr_path
    ftr_path="$(awk -F '\t' -v d="$1" '($1==d){print $3; exit}' "$KVH_HF_MAP")"
    [ -n "$ftr_path" ] && [ -f "$ftr_path" ] || return
    kvh_hf_cached_html "$ftr_path"
}

cleanup_hf_map() {
    [ -n "$KVH_HF_MAP" ] && [ -f "$KVH_HF_MAP" ] && rm -f "$KVH_HF_MAP"
    [ -n "$KVH_HF_CACHE_DIR" ] && [ -d "$KVH_HF_CACHE_DIR" ] && rm -rf "$KVH_HF_CACHE_DIR"
}

escape_xml() {
    # Escape XML special characters
    # $1 = text to escape
    local text="$1"
    text=$(printf '%s' "$text" | sed 's/&/\&amp;/g')
    text=$(printf '%s' "$text" | sed 's/</\&lt;/g')
    text=$(printf '%s' "$text" | sed 's/>/\&gt;/g')
    text=$(printf '%s' "$text" | sed 's/"/\&quot;/g')
    printf '%s' "$text"
}

date_to_rfc822() {
    # Convert YYYY-MM-DD or ISO 8601 date to RFC 822 format
    # $1 = date string
    local date_str="$1"
    
    # If it's YYYY-MM-DD format, convert to RFC 822
    if echo "$date_str" | grep -qE '^[0-9]{4}-[0-9]{2}-[0-9]{2}'; then
        # Try using date command with -d flag (GNU date)
        rfc_date=$(date -d "$date_str" "+%a, %d %b %Y %H:%M:%S %z" 2>/dev/null)
        if [ -n "$rfc_date" ]; then
            printf '%s' "$rfc_date"
        else
            # Fallback: return original date
            printf '%s' "$date_str"
        fi
    else
        printf '%s' "$date_str"
    fi
}

generate_sitemap() {
    # Generate sitemap.xml from all HTML files in destination
    # $1 = destination directory
    # $2 = base URL (optional, default: https://example.com)
    # $3 = source directory (to check for HTML files that should be excluded)
    local dst_dir="$1"
    local base_url="${2:-https://example.com}"
    local src_dir="${3:-}"
    local sitemap_file="${dst_dir}/sitemap.xml"
    
    # Remove trailing slash from base URL
    base_url="${base_url%/}"
    
    # Start XML
    {
        printf '<?xml version="1.0" encoding="UTF-8"?>\n'
        printf '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
        
        # Build find command to exclude source directory if it's within destination
        local find_cmd="find \"${dst_dir}\" -type f -name \"*.html\""
        
        # If source dir is within destination, exclude it from find
        if [ -n "$src_dir" ]; then
            local src_basename=$(basename "$src_dir")
            find_cmd="find \"${dst_dir}\" -type d -name \"${src_basename}\" -prune -o -type f -name \"*.html\" -print"
        fi
        
        # Find all HTML files in destination (excluding source directory)
        eval "$find_cmd" | sort | while IFS= read -r html_file; do
            # Get relative path from destination
            local rel_path="${html_file#$dst_dir}"
            rel_path="${rel_path#/}"
            
            # Get filename for checking
            local filename=$(basename "$html_file")
            
            # Skip pagination files (pattern: N_N.html where N is digit)
            if echo "$filename" | grep -qE '^[0-9]+_[0-9]+\.html$'; then
                continue
            fi
            
            # Skip if this HTML exists in source (wasn't generated from markdown)
            if [ -n "$src_dir" ] && [ -f "${src_dir}/${rel_path}" ]; then
                continue
            fi
            
            # Get last modified date in ISO 8601 format
            local lastmod
            lastmod=$(date -r "${html_file}" "+%Y-%m-%d" 2>/dev/null || date "+%Y-%m-%d")
            
            # Build URL
            local url="${base_url}/${rel_path}"
            
            printf '  <url>\n'
            printf '    <loc>%s</loc>\n' "$(escape_xml "$url")"
            printf '    <lastmod>%s</lastmod>\n' "$lastmod"
            printf '  </url>\n'
        done
        
        printf '</urlset>\n'
    } > "${sitemap_file}"
}

generate_rss() {
    # Generate RSS feed from .rss file
    # $1 = source .rss file
    # $2 = output .xml file
    local rss_file="$1"
    local xml_file="$2"
    
    # Extract RSS directives
    local pattern feed_title feed_desc feed_url limit
    pattern=$(awk '/<!---rss$/{p="";while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*pattern:[[:space:]]*(.+)$/,a)){p=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",p)}}print p}' "$rss_file")
    feed_title=$(awk '/<!---rss$/{while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*feed_title:[[:space:]]*(.+)$/,a)){t=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",t);print t;exit}}}' "$rss_file")
    feed_desc=$(awk '/<!---rss$/{while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*feed_description:[[:space:]]*(.+)$/,a)){d=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",d);print d;exit}}}' "$rss_file")
    feed_url=$(awk '/<!---rss$/{while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*feed_url:[[:space:]]*(.+)$/,a)){u=a[1];gsub(/^[[:space:]]+|[[:space:]]+$/,"",u);print u;exit}}}' "$rss_file")
    limit=$(awk '/<!---rss$/{l=20;while(getline>0){if($0~/^--->$/)break;if(match($0,/^[[:space:]]*limit:[[:space:]]*([0-9]+)$/,a)){l=a[1]}}print l}' "$rss_file")
    
    # Set defaults if not provided
    [ -z "$feed_title" ] && feed_title="${KVH_PAGE_NAME}"
    [ -z "$feed_desc" ] && feed_desc="${KVH_PAGE_DESC}"
    [ -z "$feed_url" ] && feed_url="https://example.com"
    [ -z "$limit" ] && limit=20
    [ -z "$pattern" ] && return
    
    # Get files matching pattern, sorted by date (newest first)
    local files
    if echo "$pattern" | grep -q '/'; then
        files=$(find "${KVH_SRC}" -type f -path "*/${pattern}" \
                ! -name "${KVH_HDR_FILE}" ! -name "${KVH_FTR_FILE}" 2>/dev/null | sort -r | head -n "$limit")
    else
        files=$(find "${KVH_SRC}" -maxdepth 1 -type f -name "${pattern}" \
                ! -name "${KVH_HDR_FILE}" ! -name "${KVH_FTR_FILE}" 2>/dev/null | sort -r | head -n "$limit")
    fi
    
    [ -z "$files" ] && return
    
    # Build RSS XML
    {
        printf '<?xml version="1.0" encoding="UTF-8"?>\n'
        printf '<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">\n'
        printf '<channel>\n'
        printf '<title>%s</title>\n' "$(escape_xml "$feed_title")"
        printf '<link>%s</link>\n' "$(escape_xml "$feed_url")"
        printf '<description>%s</description>\n' "$(escape_xml "$feed_desc")"
        printf '<lastBuildDate>%s</lastBuildDate>\n' "$(date "+%a, %d %b %Y %H:%M:%S %z")"
        printf '<language>en-us</language>\n'
        
        # Add items
        echo "$files" | while IFS= read -r file; do
            [ -z "$file" ] && continue
            
            # Get filename
            filename=$(basename "$file")
            
            # Extract date from filename (YYYY-MM-DD pattern)
            pub_date=$(echo "$filename" | grep -o '[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}')
            [ -z "$pub_date" ] && pub_date=$(date -r "$file" "+%Y-%m-%d" 2>/dev/null || true)
            
            # Convert to RFC 822
            rfc_date=$(date_to_rfc822 "$pub_date")
            
            # Get title and description from metadata
            item_title=$(getvalue "$file" "title")
            if [ -z "$item_title" ]; then
                item_title=$(echo "$filename" | sed -e 's/\.md$//' -e 's/^[0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}-//' -e 's/-/ /g')
                item_title=$(echo "$item_title" | awk '{for(i=1;i<=NF;i++)sub(/./,toupper(substr($i,1,1)),$i)}1')
            fi
            
            item_desc=$(getvalue "$file" "description")
            [ -z "$item_desc" ] && item_desc=""
            
            # Generate relative URL
            item_url=$(echo "$file" | sed -e "s|^${KVH_SRC}/||" -e 's/\.md$/.html/')
            full_url="${feed_url%/}/${item_url#./}"
            
            printf '<item>\n'
            printf '<title>%s</title>\n' "$(escape_xml "$item_title")"
            printf '<link>%s</link>\n' "$(escape_xml "$full_url")"
            [ -n "$item_desc" ] && printf '<description>%s</description>\n' "$(escape_xml "$item_desc")"
            [ -n "$rfc_date" ] && printf '<pubDate>%s</pubDate>\n' "$(escape_xml "$rfc_date")"
            printf '<guid isPermaLink="false">%s</guid>\n' "$(escape_xml "$full_url")"
            printf '</item>\n'
        done
        
        printf '</channel>\n'
        printf '</rss>\n'
    } > "$xml_file"
}

# Check if source is a file or directory
if [ -f "${KVH_SRC}" ]; then
    # Single file mode
    if [ ! "${KVH_SRC##*.}" = "md" ]; then
        printf "Error: Input file must have .md extension\n" >&2
        exit 1
    fi
    
    # Create output directory if needed
    DST_DIR="$(dirname "${KVH_DST}")"
    [ -d "${DST_DIR}" ] || mkdir -p "${DST_DIR}"
    
    PAGE_ICON="$(getvalue "${KVH_SRC}" "icon")"
    PAGE_NAME="$(getvalue "${KVH_SRC}" "title")"
    PAGE_DESC="$(getvalue "${KVH_SRC}" "description")"
    
    [ "${PAGE_ICON}" ] || PAGE_ICON="${KVH_PAGE_ICON}"
    [ "${PAGE_NAME}" ] || PAGE_NAME="${KVH_PAGE_NAME}"
    [ "${PAGE_DESC}" ] || PAGE_DESC="${KVH_PAGE_DESC}"
    
    # Escape special characters for sed
    PAGE_ICON="$(printf '%s' "${PAGE_ICON}" | sed 's/[&\|]/\\&/g')"
    PAGE_NAME="$(printf '%s' "${PAGE_NAME}" | sed 's/[&\|]/\\&/g')"
    PAGE_DESC="$(printf '%s' "${PAGE_DESC}" | sed 's/[&\|]/\\&/g')"
    
    # Process blog lists first, then convert to HTML
    PROCESSED_FILE="$(mktemp)"
    OUTPUT_BASENAME="$(basename "${KVH_DST}")"
    process_blog_lists "${KVH_SRC}" "${OUTPUT_BASENAME}" > "${PROCESSED_FILE}"
    
    # Build header/footer map and resolve for this file
    build_header_footer_map
    FILE_DIR="$(cd "$(dirname "${KVH_SRC}")" 2>/dev/null && pwd)"
    HDR_HTML="$(get_header_html "$FILE_DIR")"
    FTR_HTML="$(get_footer_html "$FILE_DIR")"
    
    # Wrap header/footer in semantic tags if present
    [ -n "$HDR_HTML" ] && HDR_HTML="<header>${HDR_HTML}</header>"
    [ -n "$FTR_HTML" ] && FTR_HTML="<footer>${FTR_HTML}</footer>"
    
    printf "%s\n" \
        "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '/PAGE_DATA/,//d')" \
        "${HDR_HTML}" \
        "$(md2html "${PROCESSED_FILE}")" \
        "${FTR_HTML}" \
        "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '0,/%PAGE_DATA%/d')" \
    | sed   -e "s|%PAGE_TITLE%|${PAGE_NAME}|g" \
            -e "s|%PAGE_DESC%|${PAGE_DESC}|g" \
            -e "s|%PAGE_ICON%|${PAGE_ICON}|g" \
            -e "s|%KVH_VERSION%|${KVH_VERSION}|g" \
    | minify_html \
    > "${KVH_DST}"
    
    rm -f "${PROCESSED_FILE}"
    
    # Generate additional paginated pages if needed
    DST_DIR="$(dirname "${KVH_DST}")"
    DST_BASE="$(basename "${KVH_DST}" .html)"
    generate_paginated_directory "${KVH_SRC}" "${DST_DIR}" "${DST_BASE}"

    cleanup_hf_map
    
elif [ -d "${KVH_SRC}" ]; then
    # Directory mode - generate html files from markdowns
    build_header_footer_map
    
    find "${KVH_SRC}" -type f -name "*.md" ! -name "${KVH_HDR_FILE}" ! -name "${KVH_FTR_FILE}" | while read -r FILE; do
        FILE_NAME="${FILE##$KVH_SRC/}"
        FILE_DIR="$(dirname "${FILE_NAME}")"

        [ -d "${KVH_DST}/${FILE_DIR}" ] \
            || mkdir -p "${KVH_DST}/${FILE_DIR}"

        PAGE_ICON="$(getvalue "${FILE}" "icon")"
        PAGE_NAME="$(getvalue "${FILE}" "title")"
        PAGE_DESC="$(getvalue "${FILE}" "description")"

        [ "${PAGE_ICON}" ] || PAGE_ICON="${KVH_PAGE_ICON}"
        [ "${PAGE_NAME}" ] || PAGE_NAME="${KVH_PAGE_NAME}"
        [ "${PAGE_DESC}" ] || PAGE_DESC="${KVH_PAGE_DESC}"
        
        # Escape special characters for sed
        PAGE_ICON="$(printf '%s' "${PAGE_ICON}" | sed 's/[&\|]/\\&/g')"
        PAGE_NAME="$(printf '%s' "${PAGE_NAME}" | sed 's/[&\|]/\\&/g')"
        PAGE_DESC="$(printf '%s' "${PAGE_DESC}" | sed 's/[&\|]/\\&/g')"
        
        # Determine output filename avoiding conflicts
        DESIRED_OUTPUT="${FILE_NAME%.md}.html"
        OUTPUT_FILE=$(get_output_filename "$DESIRED_OUTPUT")
        OUTPUT_BASENAME=$(basename "$OUTPUT_FILE")
        
        # Process blog lists first, then convert to HTML
        PROCESSED_FILE="$(mktemp)"
        process_blog_lists "${FILE}" "${OUTPUT_BASENAME}" > "${PROCESSED_FILE}"
        
        # Resolve header/footer for this file's directory
        if [ "${FILE_DIR}" = "." ]; then
            FILE_DIR_ABS="${KVH_SRC_ROOT}"
        else
            FILE_DIR_ABS="${KVH_SRC_ROOT}/${FILE_DIR}"
        fi
        HDR_HTML="$(get_header_html "$FILE_DIR_ABS")"
        FTR_HTML="$(get_footer_html "$FILE_DIR_ABS")"
        
        # Wrap header/footer in semantic tags if present
        [ -n "$HDR_HTML" ] && HDR_HTML="<header>${HDR_HTML}</header>"
        [ -n "$FTR_HTML" ] && FTR_HTML="<footer>${FTR_HTML}</footer>"

        printf "%s\n" \
            "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '/PAGE_DATA/,//d')" \
            "${HDR_HTML}" \
            "$(md2html "${PROCESSED_FILE}")" \
            "${FTR_HTML}" \
            "$(sed '0,/^__HTML TEMPLATE__$/d' "$0" | sed -e '0,/%PAGE_DATA%/d')" \
        | sed   -e "s|%PAGE_TITLE%|${PAGE_NAME}|g" \
                -e "s|%PAGE_DESC%|${PAGE_DESC}|g" \
                -e "s|%PAGE_ICON%|${PAGE_ICON}|g" \
                -e "s|%KVH_VERSION%|${KVH_VERSION}|g" \
        | minify_html \
        > "${KVH_DST}/${OUTPUT_FILE}"
        
        rm -f "${PROCESSED_FILE}"
        
        # Generate additional paginated pages if needed (use original base name)
        OUTPUT_BASE="${OUTPUT_FILE%.html}"
        OUTPUT_BASE="$(basename "$OUTPUT_BASE")"
        generate_paginated_directory "${FILE}" "${KVH_DST}/${FILE_DIR}" "${OUTPUT_BASE}"

        # Minify html files: (just removing characters within tags, not effecting JS,CSS)
        #sed -i ':a;N;$!ba;s/>\s*</></g' "${KVH_DST}/${FILE_NAME%.md}.html"

    done
    
    cleanup_hf_map
    
    # Process .rss files and generate .xml feeds
    find "${KVH_SRC}" -type f -name "*.rss" | while read -r RSS_FILE; do
        RSS_NAME="${RSS_FILE##$KVH_SRC/}"
        RSS_DIR="$(dirname "${RSS_NAME}")"
        RSS_BASE="$(basename "${RSS_NAME}" .rss)"
        
        # Ensure output directory exists
        [ "$RSS_DIR" = "." ] || mkdir -p "${KVH_DST}/${RSS_DIR}"
        
        # Generate RSS feed
        generate_rss "${RSS_FILE}" "${KVH_DST}/${RSS_DIR:+${RSS_DIR}/}${RSS_BASE}.xml"
    done

    # Copy directories (including empty ones) to destination
    find "${KVH_SRC}" -type d | while read -r DIR; do
        # Skip the root source directory itself
        [ "$DIR" = "$KVH_SRC" ] && continue
        # Compute path relative to KVH_SRC (handle with/without trailing slash)
        DIR_NAME="${DIR#$KVH_SRC}"
        DIR_NAME="${DIR_NAME#/}"
        [ -n "$DIR_NAME" ] && mkdir -p "${KVH_DST}/${DIR_NAME}"
    done
    
    # Copy non-markdown files/assets to destination (excluding header/footer markdown files)
    find "${KVH_SRC}" -type f ! -name "*.md" | while read -r FILE; do
        FILE_NAME="${FILE#$KVH_SRC}"
        FILE_NAME="${FILE_NAME#/}"
        FILE_DIR="$(dirname "${FILE_NAME}")"
        [ -d "${KVH_DST}/${FILE_DIR}" ] || mkdir -p "${KVH_DST}/${FILE_DIR}"
        cp "${FILE}" "${KVH_DST}/${FILE_NAME}"
    done
    
    # Generate sitemap.xml if enabled (when KVH_SITEMAP contains a URL)
    if [ -n "${KVH_SITEMAP}" ] && [ "${KVH_SITEMAP}" != "0" ]; then
        generate_sitemap "${KVH_DST}" "${KVH_SITEMAP}" "${KVH_SRC}"
    fi
else
    printf "Error: Source '%s' does not exist\n" "${KVH_SRC}" >&2
    exit 1
fi

exit $?

__HTML TEMPLATE__
<!DOCTYPE html>
<html lang=en>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="generator" content="Kaveh v%KVH_VERSION%" />
<meta name="description" content="%PAGE_DESC%">
<link rel="icon" href="%PAGE_ICON%">
<title>%PAGE_TITLE%</title>
<style>
    html {
        overflow-y: scroll;
    }
    body {
        background-color: #fafafa;
        color: #333;
        margin: 0 auto;
        padding: 1ex;
        max-width: 80ex;
        font-family: sans-serif;
        line-height: 1.6;
    }
    
    /* Center Images */
    img {
        display: block;
        margin: 0 auto;
        max-width: 100%;
        height: auto;
    }
    
    /* Code blocks */
    .code-block {
        background-color: #f5f5f5;
        border: 1px solid #d0d0d0;
        border-radius: 4px;
        margin: 1em 0;
        overflow: hidden;
    }
    .code-block pre {
        margin: 0;
        padding: 1em;
        overflow-x: auto;
    }
    .code-block code,
    pre {
	font-family: monospace;
	background-color: #f0f0f0;
	border: 1px solid #ccc;
	border-radius: 6px;
	padding: 1em;
	margin: 1em 0;
	font-size: 1em;
	line-height: 1.5;
	color: #222;
	white-space: pre-wrap;
	word-wrap: break-word;
	overflow-x: visible;
    }
    
    /* Inline code */
    p code, li code, td code, blockquote code {
        display: inline;
        padding: 2px 4px;
        border: 1px solid #d0d0d0;
        background-color: #e8e8e8;
        border-radius: 3px;
    }
    
    /* Headings */
    h1, h2, h3, h4, h5, h6, h7 {
        line-height: 1.2;
        margin-top: 1.5em;
        margin-bottom: 0.5em;
    }
    .heading-with-anchor {
        position: relative;
    }
    .heading-anchor {
        position: absolute;
        left: -1.5em;
        top: 50%;
        transform: translateY(-50%);
        text-decoration: none;
        opacity: 0;
        padding-right: 0.5em;
        transition: opacity 0.2s ease;
        display: inline-flex;
        align-items: center;
    }
    .heading-anchor .octicon {
        fill: #ccc;
        display: block;
    }
    .heading-with-anchor:hover .heading-anchor {
        opacity: 1;
    }
    .heading-anchor:hover .octicon {
        fill: #0066cc;
    }
    
    /* Tables */
    table {
        border-collapse: collapse;
        width: 100%;
        margin: 1em 0;
        table-layout: fixed;
    }
    table td, table th {
        border: 1px solid #ccc;
        padding: 8px 12px;
        text-align: center;
        vertical-align: center;
    }
    table tr:nth-child(even) {
        background-color: #f9f9f9;
    }
    
    /* Fix long strings in table cells */
    table td code, table th code {
        overflow-wrap: anywhere;
        word-break: break-all;
        white-space: normal;
    }
    
    /* Blockquotes */
    blockquote {
        border-left: 4px solid #d0d0d0;
        margin: 1em 0;
        padding-left: 1em;
        color: #555;
    }
    
    /* Horizontal rules */
    hr {
        border: none;
        border-top: 2px solid #ccc;
        margin: 2em 0;
    }
    
    /* Task lists */
    ul.task-list {
        list-style: none;
        padding-left: 0;
    }
    ul.task-list li.task-list-item {
        padding-left: 1.5em;
    }
    ul.task-list input[type="checkbox"] {
        margin-left: -1.5em;
        margin-right: 0.5em;
    }
    
    /* Highlight */
    mark {
        background-color: #ffff00;
        padding: 2px 0;
    }
    
    /* Strikethrough */
    del {
        text-decoration: line-through;
        opacity: 0.7;
    }
    
    /* Subscript and Superscript */
    sub, sup {
        font-size: 0.75em;
        line-height: 0;
        position: relative;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }
    
    /* Footnotes */
    .footnotes {
        margin-top: 2em;
        padding-top: 1em;
        border-top: 1px solid #ccc;
        font-size: 0.9em;
    }
    .footnotes ol {
        padding-left: 1.5em;
    }
    
    /* Definition lists */
    dl {
        margin: 1em 0;
    }
    dt {
        font-weight: bold;
        margin-top: 0.5em;
    }
    dd {
        margin-left: 2em;
        margin-bottom: 0.5em;
    }
    
    /* Links */
    a {
        color: #0066cc;
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
        color: #0052a3;
    }
    a:visited {
        color: #6b46c1;
    }
    
    /* Nested lists */
    ul ul, ol ol, ul ol, ol ul {
        margin: 0.5em 0;
    }
    
    /* Form controls */
    textarea, input, button {
        font-family: inherit;
        font-size: 1em;
        border: 1px solid #d0d0d0;
        border-radius: 4px;
        padding: 0.5em;
    }
    textarea, input[type="text"], input[type="password"], input[type="email"] {
        width: 100%;
        background-color: #fff;
        color: #333;
        box-sizing: border-box;
        margin: 0.5em 0;
    }
    textarea {
        resize: vertical;
        min-height: 4em;
    }
    button {
        background-color: #0066cc;
        color: #fff;
        border: none;
        cursor: pointer;
        padding: 0.6em 1.2em;
        margin: 0.5em 0.5em 0.5em 0;
        transition: background-color 0.2s ease;
    }
    button:hover {
        background-color: #0052a3;
    }
    button:active {
        background-color: #003d7a;
    }
    
    /* Blog post listings */
    .post-list {
        margin: 2em 0;
        padding: 1.5em;
        background-color: #f9f9f9;
        border: 1px solid #e5e5e5;
        border-radius: 6px;
    }
    .post-entry {
        margin-bottom: 2em;
        padding-bottom: 1.5em;
        border-bottom: 1px solid #e0e0e0;
    }
    .post-entry:last-of-type {
        border-bottom: none;
    }
    .post-entry h3 {
        margin-top: 0;
        margin-bottom: 0.5em;
    }
    .post-entry h3 a {
        color: #333;
    }
    .post-entry h3 a:hover {
        color: #0066cc;
    }
    .post-entry time {
        display: block;
        color: #666;
        font-size: 0.9em;
        margin-bottom: 0.5em;
    }
    .post-entry p {
        margin: 0.5em 0 0 0;
        color: #555;
    }
    .post-entry .file-icon {
        display: inline-block;
        vertical-align: middle;
        margin-right: 0.25em;
        fill: #666;
    }
    
    /* Pagination */
    .pagination {
        display: grid;
        grid-template-columns: 1fr auto 1fr;
        align-items: center;
        margin: 2em 0 0 0;
        padding: 1em 0 0 0;
        border-top: 2px solid #d0d0d0;
    }
    .pagination .prev {
        grid-column: 1;
        justify-self: start;
    }
    .pagination .page-info {
        grid-column: 2;
        text-align: center;
        color: #666;
        font-size: 0.9em;
    }
    .pagination .next {
        grid-column: 3;
        justify-self: end;
    }
    .pagination a {
        padding: 0.5em 1em;
        background-color: #0066cc;
        color: #fff;
        border-radius: 4px;
        text-decoration: none;
    }
    .pagination a:hover {
        background-color: #0052a3;
    }
    
    @media print {
        body {
            max-width: none;
        }
    }
    
    @media (prefers-color-scheme: dark) {
        body {
            color: #e0e0e0;
            background-color: #1a1a1a;
        }
        .code-block {
            background-color: #0d0d0d;
            border-color: #333;
        }
        .code-block pre {
            color: #e0e0e0;
        }
	pre {
		background-color: #1e1e1e;
		border-color: #333;
		color: #f2f2f2;
		white-space: pre-wrap;
		word-wrap: break-word;
		overflow-x: visible;
	}
        p code, li code, td code, blockquote code {
            background-color: #0d0d0d;
            border-color: #333;
            color: #e0e0e0;
        }
        table td, table th {
            border-color: #444;
        }
        table tr:nth-child(even) {
            background-color: #111;
        }
        blockquote {
            border-left-color: #444;
            color: #aaa;
        }
        hr {
            border-top-color: #444;
        }
        mark {
            background-color: #666600;
            color: #fff;
        }
        a:link {
            color: #cdf;
        }
        a:hover, a:visited:hover {
            color: #def;
        }
        a:visited {
            color: #dcf;
        }
        .footnotes {
            border-top-color: #444;
        }
        .heading-anchor .octicon {
            fill: #555;
        }
        .heading-anchor:hover .octicon {
            fill: #cdf;
        }
        textarea, input[type="text"], input[type="password"], input[type="email"] {
            background-color: #0d0d0d;
            color: #e0e0e0;
            border-color: #444;
        }
        button {
            background-color: #0066cc;
        }
        button:hover {
            background-color: #3388dd;
        }
        button:active {
            background-color: #0052a3;
        }
        .post-list {
            background-color: #0d0d0d;
            border-color: #333;
        }
        .post-entry {
            border-bottom-color: #333;
        }
        .post-entry h3 a {
            color: #e0e0e0;
        }
        .post-entry h3 a:hover {
            color: #cdf;
        }
        .post-entry time {
            color: #999;
        }
        .post-entry p {
            color: #aaa;
        }
        .pagination {
            border-top-color: #444;
        }
        .pagination a {
            background-color: #0066cc;
        }
        .pagination a:hover {
            background-color: #3388dd;
        }
        .pagination .page-info {
            color: #999;
        }
        .post-entry .file-icon {
            fill: #999;
        }
    }
</style>
</head>
<body>
<div>
%PAGE_DATA%
</div>
</body>
</html>
